
\lecture{10}{2024-10-10}{Déterminant et opération élémentaire}
\subsection{Application des opérations élémentaires sur le déterminant}
\begin{parag}{Opération sur le déterminant}
    
\begin{itemize}
    \item Type I: Interchanger des lignes entre elle ne change pas le déterminant
    \item Type II: changer le signe de la matrice change le signe du déterminant
    \item Type III: En multipliant une ligne par un scalaire $\alpha \in \mathbb{R}$ , le déterminant est aussi multiplié par ce scalaire.

     
\end{itemize}

La preuve est par récurrence, le but est d'initialiser pour des matrice $M_{2\times 2}(\mathbb{R})$ et de le prouver pour des matrice de taille $n+1\times n+1$. 
\\
On suppose donc le résultat vrai pour les matrices de taille $\leq n$ et on passe au cas $M_{n+1\times n+1}(\mathbb{R})$. Ici $n \geq 2$. Comme une opération élémentaire fait intervenir au plus deux lignes, il existe une ligne $L_i$ qui ne change pas. On développe alors det(E*A) selon $L_i$ et on obtien la même formule que $det A$, où les * où $E$ est la matrice d'une opération élémentaire sous-déterminant, det $A_{ij}$ ont été remplacés par det E'$A_{ij}$ où E' est bien une matrice d'opération élémentaire équivalente à E.
\begin{framedremark}
    On écrit parfois $det A = |A|$.
\end{framedremark}
    

\begin{subparag}{Exemple}
Le déterminant  de:
\[\begin{vmatrix}
5 & 4 & 4 & 1\\
2 & 3 & 2 & -2 \\
-5 & -7 & -6 & 9 \\
1 & -2 & -2 & -4
\end{vmatrix}\]
\\
Le but est d'avoir que deux 0 sauf à une endroit sur la ligne 2:
\\
On peut par exemple faire $C_1 - C_3$ et $C_4 + C_3$, on a:
$\begin{vmatrix}
1 & 4 & 4 & 5\\
0 & 3 & 2 & 0 \\
1 & -7 & -6 & 3 \\
3 & -2 & -2 & 2
\end{vmatrix}$ $\to 2\cdot$ $\begin{vmatrix} 
1 & 4 & 2 & 5\\
0 & 3 & 1 & 0 \\
1 & -7 & -3 & 3 \\
3 & -2 & -1 & 2
\end{vmatrix}$
\\
On sort le facteur 2 de $C_3$ et donc il faut multiplier le det avec (Type III), On fait maintenant $C_2 3C_3$:

 \[2\cdot\begin{vmatrix} 
1 & -2 & 2 & 5\\
0 & 0 & 1 & 0 \\
1 & 2 & -3 & 3 \\
3 & 1 & -1 & 2
\end{vmatrix}\]

En utilisant les cofacteur on a que:
\[ det A = 2[-0\cdot detA_{21} + 0\cdot detA_{22} -1\cdot \begin{vmatrix} 
1 & -2 & 5\\
1 & 2  & 3 \\
3 & 1  & 2
\end{vmatrix}] = -2\cdot\begin{vmatrix} 
1 & -2 & 5\\
1 & 2  & 3 \\
3 & 1  & 2
\end{vmatrix}\]
On fait le même procédé ($L_2 - L_1$ et $L_3 - 3L_1$):
\[ -2\cdot\begin{vmatrix} 
1 & -2 & 5\\
1 & 2  & 3 \\
3 & 1  & 2
\end{vmatrix} \to -2\cdot\begin{vmatrix} 
1 & -2 & 5\\
0 & 4  & -2 \\
0 & 7  & -13
\end{vmatrix}\]
Ce qui nous donne à la fin:
\[ = -2\cdot 1 \cdot \begin{vmatrix}
    4 & -13 \\
    7 & -13
\end{vmatrix} = -2\cdot 1 [-52 + 14] = 76\]



    
\end{subparag}
\end{parag}
\begin{parag}{Propriétés du déterminant}
    

\\

Soit $A$ une matrice de taille $n \times n$ et $\lambda \in \mathbb{R}$ Alors, $det (\lambda A) = \lambda^n \cdot det A $.
\begin{preuve}
    $\lambda \cdot A$ est obtenu de $A$ en effectuant $n$ opération élémentaires de type III (sur chacune des lignes).
    \end{preuve}
    \begin{framedremark}
        Si une ligne de $A$ est combinaison linéaire des autres lignes, alors $det A = 0$.
    \end{framedremark}
    \begin{theoreme}
        Une matrice carrée est inversible si et seulement si det$A \neq 0$.
    \end{theoreme}
    \begin{preuve}
        Une matrice carré est inversible $n\times n$ iff elle a $n$ pivots iff il existe des opérations élémentaires qui transforment A en une matrice échelonnée avec des pivots, non nuls, sur la diagonale.
        \\
        Le déterminant de cette matrice est le produit des termes de la diagonale, et il est non nul, donc $det A \neq 0$.
    \end{preuve}
    \begin{framedremark}
        Le déterminant a peut être changé de signe ou été multiplié par $\alpha \neq 0$, mais il reste $\neq 0$.
    \end{framedremark}
    
    \begin{theoreme}
        $det(A^t) = detA$
    \end{theoreme}
    \begin{preuve}
        Le développement du déterminant de $A$ selon la première ligne est identique au développement du déterminant de sa transposée selon la première colonne.
    \end{preuve}
    \begin{thm}
        Soit $A$ et $B$ deux matrices $n\times n$. Alors: 
        \\
        \[det(AB) = detA \cdot det B\]

    \end{thm}
    \begin{preuve}
        La preuve se fait en deux parties selon les deux cas où la matrice est inversible ou non.
        \begin{itemize}
            \item Supposons que $A$ soit inversible. Alors nous savons que $A$ peut s'écrire comme produit des matrices élémentaires. La preuve se fait par induction sur le nombre de matrices élémentaires.
            \item Pour initialiser l'induction on doit traiter le cas où $A$ est une matrice élémentaire. Il y a donc trois sous-cas.

        \end{itemize}
    \end{preuve}
    \begin{enumerate}
        \item $A = E_{ij}(\lambda)$ est de type I. Comme elle est triangulaire et que sa diagonale est constituée de 1, on a à $det(E_{ij}(\lambda) = 1$. Il faut encore calculer $det(E_{ij}(\lambda)B)$. \\ 
        On peut le faire car comme la matrice est triangulaire supérieur, sont déterminant ne veux seulement le produit des éléments qui sont trouvent dans sa diagonales (que des $1$ dans notre cas) et donc:
        \\ 
        \[\det(E_{ij}(\lambda)\cdot B) = \det E_{ij}(\lambda)\cdot \det B = 1 \cdot \det B\]
        \item $A = E_{ij}$, $det E_{ij} = -1$ car c'est $I_n$ avec $L_i$ et $L_j$ échangées.
        \item $A = E_i(\lambda)$, $det(E_i(\lambda) = \lambda$ (diagonale. $det(E_i(\lambda)\cdot B) = \lambda \cdot detB = det E_{j}(\lambda)\cdot det B$.


    \end{enumerate}
    \textbf{Hypothèse de récurrence} : \[ det(AB) = det A \cdot det B\]
    Pour toutes les matrices $A$ qui sont produits d'au plus $n$ matrices élémentaires.
    \\
    \textbf{Pas de récurrence}. Considérons une matrice $A = E_{n+1} \cdot E_n ...$, qui est le produit de $n + 1$ matrices élémentaires. Nous devons montrer que:
    \[
    det(E_{n+1}\cdot E_n ... E_1 \cdot B) =  det(E_{n+1}\cdot E_n ... E_1)\cdot B    \]
    On sait que $det( E_n ... E_1) = C$ donc $det(E_{n+1}\cdot E_n ... E_1 \cdot B) = det(E_{n+1}) \cdot C$.
    On fait la suite jusqu'à trouver : \[
    det(E_{n+1}\cdot E_n ... E_1)\cdot B
    \]

    \paragraph{$2^{e}$ cas: } $A$ non inversible, Alors par le théorème précédent, $det A = 0$. Donc $det(A) \cdot det(B) = 0$.\\
    On montre que $A\cdot B $ n'est pas inversible si bien que $det(A\cdot B) = 0$. Si $AB$ est inversible il existe $C$ tel que $(AB)C = I_n$ et $A(BC) = I_n$ mais on sait que $A$ n'est pas inversible, \textbf{Contradiction}.
    \\
    \begin{corollaire}
       Si $A$ est inversibles, alors
       \[\det A^{-1} = \frac{1}{\det A}\]
    \end{corollaire}  
    \begin{framedremark}
        Même si en général $AB \neq BA$ on a toujours $det(AB) = (detBA)$ car les deux déterminants donnent $det A \cdot det B = det B \cdot det A$.
    \end{framedremark}
    \begin{framedremark}
        
    
        Attention : \[ det(A + B) \neq det A + det B\]
        Le déterminant n'est pas \textbf{linéaire} comme application, $det : M{n\times n} \to \mathbb{R}$.
    
    \end{framedremark}
\end{parag}

    \paragraph{Linéarité du déterminant comme fonction \textbf{d'une colonne}}
    Le déterminant est linéaire comme fonction d'une colonne, pour cela nous devons vérifier:
    \begin{enumerate}
        \item $T(\vec{0}) = 0$ car c'est le déterminant d'une matrice ayant une colonne nulle.
        \item $T(\lambda\vec{x}) = \lambda T(\vec{x})$ car il s'agit d'une opération de type III sur la $j^{eme}$ colonne.
        \item $T(\vec{x}+ \vec{y}) = T(\vec{x}) + T(\vec{y})$ se prouve en développant le déterminant selon la $j^{eme}$ colonne.

    \end{enumerate}


    $A  \in M_{3\times3}(\mathbb{R})$, il faut alors tout développé mais faut juste le faire avec la commutativé et distributivité dans les nombres réels.

    \paragraph{Règles de Charmer}
    \begin{theoreme}
    Si $det A = ad-bc \neq 0$, le système
    \begin{align*}
        ax + by &= e\\
        cx + dy &= f
    \end{align*}
    A une solution unique (qu'on trouve grâce à la matrice inverse)
    \end{theoreme}
    \\
    
la solution du système est $A^{-1}\vec{b}$: 
\[\frac{1}{ad -bc}\begin{pmatrix}
    d & -b \\
    -c & a
\end{pmatrix}
\begin{pmatrix}
    e \\
    f
\end{pmatrix}\]
Alors : 
\[x = \frac{ed -bf}{ad -b} =  \frac{det\begin{pmatrix}
    e & b \\
    f & d
\end{pmatrix}} {det A}\]
Et:
\[
y = \frac{af - ec}{ad - bc} = \frac{det \begin{pmatrix}
    a & e \\
    c & f
\end{pmatrix}}{det A}
\]
Soit $A$ une matrice carrée \textbf{inversible}. Pour tout vecteur $\vec{b}$ on pose :
\[A_i\vec{b} = (\vec{a_1}... \vec{a}_{i-1} \vec{b} \vec{a}_{i+ 1} ... \vec{a}_n)\]

    La seul solution du système $A\vec{x} = \vec{b}$ est donnée par la formule : 
    \[
    x_i = \frac{detA_i(\vec{b})}{det A}
    \]
\subparagraph{Preuve.}
Soit $B_i = (I_n)_i(\vec{x}) = (\vec{e}_1,\dots, \vec{e}_{i-1}, .., \vec{e}_{i+1}, .., \vec{e}_n  )$.
\\
La ligne $L_i$ est constituées de zéros, saut le coefficient $x_i$ en position $(i, i)$, si bien que $\det (B_i) = x_i$.
\\
$A$ étant inversible, la solution unique est:
\[\vec{a} = A^{-1}\vec{b}\]
\\
Soit $B_i = (I_n)_i(\vec{x}) = (\vec{e}_1,\dots, \vec{e}_{i-1}, .., \vec{e}_{i+1}, .., \vec{e}_n)$.
\\
\[\det B_i = x_i\]
On calcule:
\\
\begin{align*}
A\cdot B_i &= A\cdot(\vec{e}_1, ..., \vec{x}, ..., \vec{e}_n)\\
&= (A\cdot\vec{e}_1, ..., A\cdot\vec{x}, ..., A\vec{e}_n)\\
&= (\vec{a}_1, ..., \vec{b} .., \vec{a}_n)    
\end{align*}
\\
Ainsi \[\det(A_i(\vec{b})) = \det(A\cdot B_i) = \det A \cdot \det B_i\]
\\
En divisant par $\det A \neq 0$, on obtient notre formule:
    \[
    x_i = \frac{detA_i(\vec{b})}{det A}
    \]